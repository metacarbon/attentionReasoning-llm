# Attention-Driven Reasoning: Unlocking the Potential of Large Language Models 
[[paper](http://arxiv.org/abs/2403.14932)]

## Abstract
Large Language Models (LLMs) have shown remarkable capabilities, but their reasoning abilities and underlying mechanisms remain poorly understood. We present a novel approach to enhance LLMs’ reasoning through attention mechanism optimization, without additional training data. We identify inefficiencies in the attention distribution caused by non-semantic tokens and propose an algorithm to re-balance the skewed distribution, enabling the model to abstract more nuanced knowledge. Our experiments demonstrate significantly improved reasoning capabilities, particularly for non-STEM questions. We provide insights into the role of attention patterns in LLMs’ reasoning and propose a method to enhance these abilities, paving the way for more powerful and versatile language models.

## Usage

### Environment Setup

```bash
conda create -n attllm python=3.8
conda activate attllm

pip install torch torchvision torchaudio
pip install transformers==4.33.0 accelerate datasets scipy sentencepiece
```
### Prepare Weights
Download the Llama-2-7B-chat-hf weights (.bin files) into the /Llama-2-7B-chat-hf folder.

### Test MMLU

```bash
CUDA_VISIBLE_DEVICES=0 python eval_chat_mmlu.py  --enable_cot
```
Please note that the MMLU test script uses regex to extract the answer generated by the LLM. When using Chain-of-Thought (CoT) reasoning, this can cause inaccuracies. In our paper, we manually checked the generated answers to ensure accuracy. The manually checked results are also uploaded in the /outs_chat folders.

## Citation

If you find our works useful or relevant to your project and research, please kindly cite our paper:

```bibtex
@article{liao2024attentiondriven,
        title={Attention-Driven Reasoning: Unlocking the Potential of Large Language Models},
        author={Bingli Liao and Danilo Vasconcellos Vargas},
        journal={arXiv},
        year={2024}
        }
```